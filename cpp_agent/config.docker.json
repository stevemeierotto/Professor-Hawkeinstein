{
  "llama_server_url": "http://llama-server:8090",
  "model_name": "llama-2-7b-chat",
  "server_port": 8080,
  "models_base_path": "/app/models",
  "default_model": "llama-2-7b-chat.Q4_0.gguf",
  
  "_comment_multi_model": "Set multi_model_enabled to true to load multiple models (requires more RAM)",
  "multi_model_enabled": false,
  
  "models": {
    "qwen2.5-1.5b-instruct-q4_k_m.gguf": {
      "port": 8090,
      "file": "qwen2.5-1.5b-instruct-q4_k_m.gguf",
      "ctx_size": 4096,
      "threads": 4
    },
    "llama-2-7b-chat.Q4_0.gguf": {
      "port": 8090,
      "file": "llama-2-7b-chat.Q4_0.gguf",
      "ctx_size": 4096,
      "threads": 4
    }
  },
  "database": {
    "host": "database",
    "port": 3306,
    "name": "professorhawkeinstein_platform",
    "user": "professorhawkeinstein_user",
    "password": "BT1716lit"
  },
  "agent": {
    "max_context_length": 4096,
    "temperature": 0.7,
    "top_k": 40,
    "top_p": 0.9
  }
}
